global:
  scrape_interval: 15s
  evaluation_interval: 15s

scrape_configs:
  - job_name: 'prometheus'
    static_configs:
      - targets: ['localhost:9090']

  # Scrape each cluster node via /scrape endpoint
  # Note: 'redis-cluster' job removed - it was redundant and caused duplicate metrics
  - job_name: 'redis-cluster-nodes'
    static_configs:
      - targets:
        - '172.30.0.11:7001'
        - '172.30.0.12:7002'
        - '172.30.0.13:7003'
        labels:
          project: 'g01'  # 项目标签，用于 Grafana 按项目过滤
    metrics_path: /scrape
    relabel_configs:
      - source_labels: [__address__]
        target_label: __param_target
        replacement: 'redis://${1}'
      - source_labels: [__address__]
        target_label: instance
      - target_label: __address__
        replacement: 'redis_exporter:9121'
    params:
      # 队列监控配置 (check-keys 参数)
      # 空字符串表示不监控: check-keys: [""]
      #
      # 示例1: 监控指定队列 (推荐，性能好)
      # check-single-keys: ["db0=queue:orders,db0=queue:emails,db0=celery"]
      #
      # 示例2: 模式匹配监控所有队列 (大库慎用，会 SCAN 整个库)
      # check-keys: ["db0=queue:*"]
      #
      # 示例3: 监控所有 list 类型的 key (非常耗性能，仅测试用)
      # check-keys: ["db0=*"]
      #
      check-keys: [""]

